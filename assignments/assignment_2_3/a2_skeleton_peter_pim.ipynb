{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "730fd591",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/vlamen/tue-deeplearning/blob/main/assignments/assignment_2_3/a2_skeleton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32f8d18",
   "metadata": {},
   "source": [
    "# Group Number: 37\n",
    "# Student 1: Jiong Li | 1533312\n",
    "# Student 2: Peter Elmers | 1734350\n",
    "# Student 3: P.T.C.M. Tholhuijsen | 1237447"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faec2056",
   "metadata": {},
   "source": [
    "# Downloading Data and Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d0580a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "\n",
    "from zipfile import ZipFile\n",
    "import requests\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0756591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_zip(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    zipf = ZipFile(io.BytesIO(response.content))\n",
    "    return {name: zipf.read(name) for name in zipf.namelist()}\n",
    "\n",
    "def load_array(zipfile, fn):\n",
    "    return np.load(io.BytesIO(zipfile[fn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb77a4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of the training data:\n",
      "\n",
      "positions: (10000, 4, 2, 5)\n",
      "velocities: (10000, 1, 2, 5)\n",
      "charges: (10000, 5, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell loads the training, validation or test data as numpy arrays,\n",
    "with the positions, initial velocities and charge data of the particles.\n",
    "\n",
    "The position arrays are shaped as\n",
    "[simulation id, time point (corresponding to t = 0, 0.5, 1 or 1.5), x/y spatial dimension, particle id].\n",
    "\n",
    "The initial velocity arrays are shaped as\n",
    "[simulation id, 1 (corresponding to t=0), x/y spatial dimension, particle id].\n",
    "\n",
    "The charge arrays are shaped as [simulation id, particle id, 1]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "data = load_zip('https://surfdrive.surf.nl/files/index.php/s/OIgda2ZRG8v0eqB/download')\n",
    "\n",
    "features = ['positions', 'velocities', 'charges']\n",
    "    \n",
    "positions_train, velocities_train, charges_train = (load_array(data, f'data/train/{f}.npy') for f in features)\n",
    "positions_valid, velocities_valid, charges_valid = (load_array(data, f'data/valid/{f}.npy') for f in features)\n",
    "positions_test, velocities_test, charges_test = (load_array(data, f'data/test/{f}.npy') for f in features)\n",
    "\n",
    "print('Shapes of the training data:\\n')\n",
    "print(f'positions: {positions_train.shape}')\n",
    "print(f'velocities: {velocities_train.shape}')\n",
    "print(f'charges: {charges_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c3ea4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example of retrieving data from the arrays:\n",
      "\n",
      "\n",
      "In simulation 42 of the training set, particle 3 with charge -1.0 had coordinates [ 2.05159559 -1.46130851].\n",
      "The initial velocity of this particle was [ 0.28402364 -0.24784824].\n"
     ]
    }
   ],
   "source": [
    "print('An example of retrieving data from the arrays:\\n\\n')\n",
    "\n",
    "sim_idx = 42\n",
    "t_idx = 2  # t_idx 0, 1, 2, 3 corresponds to t=0, 0.5, 1 and 1.5 respectively\n",
    "spatial_idx = (0,1)  # corresponds to both x and y dimension\n",
    "particle_idx = 3  # corresponds to particle with index 3\n",
    "\n",
    "p = positions_train[sim_idx, t_idx, spatial_idx, particle_idx]\n",
    "v = velocities_train[sim_idx, 0, spatial_idx, particle_idx]  # note: this array contains only the inital velocity -> hence the 0\n",
    "c = charges_train[sim_idx, particle_idx, 0] \n",
    "\n",
    "print(\n",
    "    f'In simulation {sim_idx} of the training set, particle {particle_idx} with charge {c} had coordinates {p}.\\nThe initial velocity of this particle was {v}.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10a3438a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview of no. datapoints:\n",
      "\n",
      "10000 train, 2000 validation, 2000 test simulations\n"
     ]
    }
   ],
   "source": [
    "print('Overview of no. datapoints:\\n')\n",
    "\n",
    "print(f'{len(positions_train)} train, {len(positions_valid)} validation, {len(positions_test)} test simulations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9106543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example(pos, vel):\n",
    "\n",
    "    fig = plt.figure()\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([-5., 5.])\n",
    "    axes.set_ylim([-5., 5.])\n",
    "    colors = ['red', 'blue', 'green', 'orange', 'brown']\n",
    "    for i in range(pos.shape[-1]):\n",
    "        plt.plot(pos[0, 0, i], pos[0, 1, i], 'd', color=colors[i])\n",
    "        plt.plot(pos[-1, 0, i], pos[-1, 1, i], 'x', color=colors[i])\n",
    "        plt.plot([pos[0, 0, i], pos[0, 0, i] + vel[0, 0, i]], [pos[0, 1, i], pos[0, 1, i] + vel[0, 1, i]], '--', color=colors[i])\n",
    "    fig.set_size_inches(7, 7)\n",
    "    plt.xlim(np.min(pos)-1, np.max(pos) +1)\n",
    "    plt.ylim(np.min(pos)-1, np.max(pos) +1)\n",
    "    plt.plot([], [], 'd', color='black', label='initial position')\n",
    "    plt.plot([], [], 'x', color='black', label='final position')\n",
    "    plt.plot([], [], '--', color='black', label='initial velocity \\ndirection and magnitude')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d28681a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_idx = np.random.randint(0, 10000)\n",
    "plot_example(positions_train[random_idx], velocities_train[random_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059b633c",
   "metadata": {},
   "source": [
    "# Data Handling and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6ecb529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is set to cuda\n"
     ]
    }
   ],
   "source": [
    "# Pick the best device\n",
    "import torch\n",
    "\n",
    "def try_device(device):\n",
    "    # Try to put an array on given device. If successful, return device. Else, 'cpu'.\n",
    "    x = torch.ones((1,))\n",
    "    try:\n",
    "        x.to(device)\n",
    "        return device\n",
    "    except:\n",
    "        return 'cpu'\n",
    "\n",
    "device = try_device('cuda')\n",
    "if device == 'cpu':\n",
    "    device = try_device('mps')\n",
    "\n",
    "print(f'Device is set to {device}')\n",
    "\n",
    "# Move all the little craps into torch things on the device\n",
    "p_train, v_train, c_train = [torch.Tensor(vec).to(device=device) for vec in [positions_train, velocities_train, charges_train]]\n",
    "p_valid, v_valid, c_valid = [torch.Tensor(vec).to(device=device) for vec in [positions_valid, velocities_valid, charges_valid]]\n",
    "p_test, v_test, c_test = [torch.Tensor(vec).to(device=device) for vec in [positions_test, velocities_test, charges_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8633eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a baseline: particle position = velocity * time + initial\n",
    "def baseline_predict(p0, v0, time):\n",
    "    '''\n",
    "    Return a numpy array of predicted x, y position of each particle in p0.\n",
    "    Given p0 starting locations, v0 starting velocities, and time to predict.\n",
    "    Result is computed via linear projection: v0 * time + p0.\n",
    "    Where p0 and v0 are both (N x 1 x 2 x P) tensors, for N simulations, P particles/sim\n",
    "    '''\n",
    "    return p0 + v0 * time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a99a32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline error should be 0: {'rms': 0.0}\n",
      "Error over time should increase (train).\n",
      "t = 0.5 {'rms': 0.2483280450105667}\n",
      "t = 1 {'rms': 0.5178293585777283}\n",
      "t = 1.5 {'rms': 0.7917788624763489}\n",
      "Error over time should increase (valid).\n",
      "t = 0.5 {'rms': 0.2483280450105667}\n",
      "t = 1 {'rms': 0.5178293585777283}\n",
      "t = 1.5 {'rms': 0.7917788624763489}\n",
      "Error over time should increase (test).\n",
      "t = 0.5 {'rms': 0.2483280450105667}\n",
      "t = 1 {'rms': 0.5178293585777283}\n",
      "t = 1.5 {'rms': 0.7917788624763489}\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Evaluate the baseline model (what metrics? r2? rms?)\n",
    "def rms(p_pred, p_actual):\n",
    "    '''\n",
    "    Return the root mean squared distance between predicted locations and actual locations.\n",
    "    Where p_pred and p_actual are both (N x T x 2 x P) tensors.\n",
    "    '''\n",
    "    mse = nn.MSELoss()\n",
    "    return mse(p_pred, p_actual).sqrt().item()\n",
    "\n",
    "def baseline_evaluate(p, v, time):\n",
    "    '''\n",
    "    Evaluate the baseline \"model\" at given time in {0, 0.5, 1, 1.5}.\n",
    "    '''\n",
    "    p_pred = baseline_predict(p[:, :1, :, :], v, time)\n",
    "    idx = int(time / 0.5)\n",
    "    p_actual = p[:, idx:idx+1, :, :]\n",
    "    # Currently just rms, but we could add more evaluations\n",
    "    return {'rms': rms(p_pred, p_actual)}\n",
    "\n",
    "print('Baseline error should be 0:', baseline_evaluate(p_train, v_train, 0))\n",
    "\n",
    "# Print some more metrics\n",
    "for klass in ['train', 'valid', 'test']:\n",
    "    p_klass, v_klass = locals()[f'p_{klass}'], locals()[f'v_{klass}']\n",
    "    print(f'Error over time should increase ({klass}).')\n",
    "    for t in [0.5, 1, 1.5]:\n",
    "        print(f't = {t}', baseline_evaluate(p_train, v_train, t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b2874d",
   "metadata": {},
   "source": [
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3aa472dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33b0e1c",
   "metadata": {},
   "source": [
    "Implementation like https://github.com/higgsfield/interaction_network_pytorch/blob/master/Interaction%20Network.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e79124e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.9361, -0.2276, -0.7878,  0.0267, -1.0000],\n",
      "        [ 3.6532, -2.7631,  1.5892, -0.4211,  1.0000],\n",
      "        [-4.5496,  8.2998, -1.2906,  2.3834,  1.0000],\n",
      "        [-3.0958, -3.0921, -1.9173, -0.5785,  1.0000],\n",
      "        [ 0.1073, -2.8976,  0.6539, -0.5676, -1.0000]], device='cuda:0')\n",
      "tensor([[-1.9361, -0.2276],\n",
      "        [ 3.6532, -2.7631],\n",
      "        [-4.5496,  8.2998],\n",
      "        [-3.0958, -3.0921],\n",
      "        [ 0.1073, -2.8976]], device='cuda:0')\n",
      "tensor([[-0.7878,  0.0267],\n",
      "        [ 1.5892, -0.4211],\n",
      "        [-1.2906,  2.3834],\n",
      "        [-1.9173, -0.5785],\n",
      "        [ 0.6539, -0.5676]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in zip(p_train, v_train, c_train):\n",
    "    p = torch.transpose(i[0][0], 0, 1)\n",
    "    v = torch.transpose(i[1][0], 0, 1)\n",
    "    c = i[2]\n",
    "   \n",
    "    data = torch.hstack((p, v, c))\n",
    "    print(data)\n",
    "    print(data[:, 0:2])\n",
    "    print(data[:, 2:4])\n",
    "    # x_p, y_p, x_v, y_v, c\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c34a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relation-centric neural network\n",
    "class RelationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RelationalModel, self).__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear()\n",
    "            nn.ReLU()\n",
    "            nn.Linear()\n",
    "            nn.ReLU()\n",
    "            nn.Linear()\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        _, n_relations, input_size = x.size()\n",
    "        x = x.view(-1, input_size)\n",
    "        self.layers(x)\n",
    "        x = x.view(5, n_relations, self.output_size)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "587da524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# object-centric acceleration neural network\n",
    "class AccelerationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AccelerationModel, self).__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(5, 25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(25, 2),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, delta_t):\n",
    "        x = x.view(-1, 5)\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bca2f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# object-centric velocity neural network\n",
    "class VelocityModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VelocityModel, self).__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(4, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 2),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, delta_t):\n",
    "        x = x.view(-1, 4)\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3535d8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# object-centric position neural network\n",
    "class PositionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PositionModel, self).__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(4, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 2),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, delta_t):\n",
    "        x = x.view(-1, 4)\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22703713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# object-centric neural network for accelleration, velocity and position\n",
    "class ObjectModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ObjectModel, self).__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(, 2),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, x.size(2))\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e9bdf5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InteractionNetwork(\n",
       "  (acceleration_model): AccelerationModel(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=5, out_features=25, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=25, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (velocity_model): VelocityModel(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=16, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=16, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (position_model): PositionModel(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=16, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=16, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# interaction network\n",
    "class InteractionNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InteractionNetwork, self).__init__()\n",
    "        \n",
    "        self.acceleration_model = AccelerationModel()\n",
    "        self.velocity_model = VelocityModel()\n",
    "        self.position_model = PositionModel()\n",
    "        \n",
    "    def forward(self, x, delta_t):\n",
    "        pred_accelleration = self.acceleration_model(x, delta_t)\n",
    "        pred_velocity = self.velocity_model(torch.hstack((x[:, 2:4], pred_accelleration)), delta_t)\n",
    "        pred_position = self.position_model(torch.hstack((x[:, 0:2], pred_velocity)), delta_t)\n",
    "        return pred_position\n",
    "    \n",
    "interaction_network = InteractionNetwork()\n",
    "interaction_network.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd80a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:26<04:02, 26.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.028501021920320106\n",
      "val loss: 0.0055784383329097265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 2/10 [00:53<03:32, 26.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.005523326100378168\n",
      "val loss: 0.005127389508800122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▉                                                          | 3/10 [01:18<03:01, 25.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.005132827079014086\n",
      "val loss: 0.004941165196261133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 4/10 [01:44<02:35, 25.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.005012398006753348\n",
      "val loss: 0.0048761450180725635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [02:11<02:11, 26.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.004966070405560324\n",
      "val loss: 0.004858449660887708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [02:36<01:44, 26.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.004924934002562346\n",
      "val loss: 0.004823001107620083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [03:03<01:18, 26.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.004889257285125793\n",
      "val loss: 0.004816908228181998\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(interaction_network.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "criterion.to(device=device)\n",
    "\n",
    "train_loss_graph, val_loss_graph = list(), list()\n",
    "for epoch in tqdm(range(10)):\n",
    "    train_loss, val_loss = list(), list()\n",
    "    \n",
    "    interaction_network = interaction_network.train()\n",
    "    for i in zip(p_train, v_train, c_train):\n",
    "        p = torch.transpose(i[0][0], 0, 1)\n",
    "        v = torch.transpose(i[1][0], 0, 1)\n",
    "        c = i[2]\n",
    "\n",
    "        data = torch.hstack((p, v, c))\n",
    "        # x_p, y_p, x_v, y_v, c\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y_pred = interaction_network(data, 0.5)\n",
    "        loss = criterion(y_pred, torch.transpose(i[0][1], 0, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss.append(loss.item() / 5)\n",
    "    \n",
    "    train_loss_graph.append(sum(train_loss) / len(p_train))\n",
    "    \n",
    "    interaction_network = interaction_network.eval()\n",
    "    for i in zip(p_valid, v_valid, c_valid):\n",
    "        p = torch.transpose(i[0][0], 0, 1)\n",
    "        v = torch.transpose(i[1][0], 0, 1)\n",
    "        c = i[2]\n",
    "\n",
    "        data = torch.hstack((p, v, c))\n",
    "        # x_p, y_p, x_v, y_v, c\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y_pred = interaction_network(data, 0.5)\n",
    "        loss = criterion(y_pred, torch.transpose(i[0][1], 0, 1))\n",
    "        \n",
    "        val_loss.append(loss.item() / 5)\n",
    "    \n",
    "    val_loss_graph.append(sum(val_loss) / len(p_valid))\n",
    "        \n",
    "    print(f'Average loss: {train_loss_graph[-1]}')\n",
    "    print(f'val loss: {val_loss_graph[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02d1d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_loss_graph)\n",
    "plt.title(\"training loss\")\n",
    "plt.xlabel(\"epoch number\")\n",
    "plt.ylabel(\"loss value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f2a2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(val_loss_graph)\n",
    "plt.title(\"validation loss\")\n",
    "plt.xlabel(\"epoch number\")\n",
    "plt.ylabel(\"loss value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4134d8dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (709580910.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [19]\u001b[1;36m\u001b[0m\n\u001b[1;33m    nn.Dense(features=25)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class PINN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PINN, self).__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Dense(features=25)\n",
    "            nn.tanh()\n",
    "            nn.Dense(features=25)\n",
    "            nn.tanh()\n",
    "            nn.Dense(features=25)\n",
    "            nn.tanh()\n",
    "            nn.Dense(features=25)\n",
    "            nn.tanh()\n",
    "            nn.Dense(features=25)\n",
    "            nn.tanh()\n",
    "            nn.Dense(features=25)\n",
    "            nn.Linear(25)\n",
    "        )\n",
    "        self.delta_t = 0.001\n",
    "        \n",
    "    def calc_acc(self, x, c, t):\n",
    "        torch.autograd.grad(x, c, t)\n",
    "        \n",
    "    def calc_pos(self, x, v, t):\n",
    "        torch.autograd.grad()\n",
    "        \n",
    "        a = torch.sum([force for force in forces])\n",
    "        v_new = v + a * self.delta_t\n",
    "        new_pos = x + v_new * self.delta_t\n",
    "        return new_x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66774050",
   "metadata": {},
   "outputs": [],
   "source": [
    "acceleration[i][t] = sum([force for force in forces[i][t-delta_t]])\n",
    "velocity[i][t] = velocity[i][t-delta_t] + acceleration[i][t] * delta_t\n",
    "position[i][t] = position[i][t-delta_t] + velocity[i][t] * delta_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba598378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 0.28550369, -2.83026035, -4.09011954,  5.86690925,\n",
       "           3.34592891],\n",
       "         [ 2.67076836, -0.24677496, -4.93502862,  3.56697064,\n",
       "          -2.23848025]],\n",
       " \n",
       "        [[ 0.32519777, -3.327417  , -4.72231886,  6.94438172,\n",
       "           3.9414407 ],\n",
       "         [ 3.06141083, -0.36164926, -5.89177367,  4.01903033,\n",
       "          -2.57050795]],\n",
       " \n",
       "        [[ 0.36478959, -3.83607425, -5.36116502,  8.03212461,\n",
       "           4.54493177],\n",
       "         [ 3.4649563 , -0.47540496, -6.85987972,  4.4777738 ,\n",
       "          -2.91188004]],\n",
       " \n",
       "        [[ 0.40424833, -4.35349455, -6.00493702,  9.12768574,\n",
       "           5.15442658],\n",
       "         [ 3.87835058, -0.58833091, -7.83660568,  4.94159813,\n",
       "          -3.26039165]]]),\n",
       " array([[[ 0.07945439, -0.98033438, -1.25614375,  2.14243246,\n",
       "           1.18123603],\n",
       "         [ 0.76562579, -0.23114694, -1.89962386,  0.89597175,\n",
       "          -0.65271654]]]),\n",
       " array([[-1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [-1.]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions_train[1000], velocities_train[1000], charges_train[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "596f3929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions_train[998].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95154df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 2, 5), (1, 2, 5), (5, 1))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The position arrays are shaped as\n",
    "# [simulation id, time point (corresponding to t = 0, 0.5, 1 or 1.5), x/y spatial dimension, particle id].\n",
    "\n",
    "# The initial velocity arrays are shaped as\n",
    "# [simulation id, 1 (corresponding to t=0), x/y spatial dimension, particle id].\n",
    "\n",
    "# The charge arrays are shaped as [simulation id, particle id, 1]\n",
    "\n",
    "positions_train[1000].shape, velocities_train[1000].shape, charges_train[1000].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea70d73",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3af520ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95af5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e03ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5fb3b29",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf5fa1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:\n",
    "# The amount of training samples should vary from 100 to 10000, and the\n",
    "# prediction horizons are t = 0.5, t = 1 and t = 1.5. For each training set\n",
    "# size/time horizon combination, compare to a simple linear baseline where\n",
    "# xti = x0i + v0i ·t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2280031f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Come up with and execute one additional experiment that provides an interesting insight in your method\n",
    "# possible idea: interpolation, i.e. given t = 1.5 and t = 0.5, where is it at t = 1?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8240f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "27c164e33ceb3372f7d05cab3554d1b7111f26924d32637c2cc5dd0d753ab5f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
