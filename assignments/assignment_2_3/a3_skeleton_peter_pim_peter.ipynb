{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "963690b2",
      "metadata": {
        "id": "963690b2"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vlamen/tue-deeplearning/blob/main/assignments/assignment_2_3/a3_skeleton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd8459f1",
      "metadata": {
        "id": "bd8459f1"
      },
      "source": [
        "# Group Number:\n",
        "\n",
        "# Student 1:\n",
        "\n",
        "# Student 2:\n",
        "\n",
        "# Student 3:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dde28458",
      "metadata": {
        "id": "dde28458"
      },
      "source": [
        "# Downloading Data and Preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7d0580a5",
      "metadata": {
        "id": "7d0580a5"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "\n",
        "from zipfile import ZipFile\n",
        "import requests\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8ce00edc",
      "metadata": {
        "id": "8ce00edc"
      },
      "outputs": [],
      "source": [
        "def load_zip(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    zipf = ZipFile(io.BytesIO(response.content))\n",
        "    return {name: zipf.read(name) for name in zipf.namelist()}\n",
        "\n",
        "def load_pickle(zipfile, fn):\n",
        "    return pickle.load(io.BytesIO(zipfile[fn]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bb77a4be",
      "metadata": {
        "id": "bb77a4be"
      },
      "outputs": [],
      "source": [
        "data = load_zip('https://surfdrive.surf.nl/files/index.php/s/cwqGaS22KXgnXtg/download')\n",
        "\n",
        "    \n",
        "\"\"\"\n",
        "simulation_{train, valid, test} is stored as a list of simulations. \n",
        "Each simulation is a numpy array of size (t, 2): For t timesteps an x and y coordinate of our particle.\n",
        "\"\"\"\n",
        "simulation_train = load_pickle(data, 'data/train/simulation.pickle')  # 3.1 + 3.2\n",
        "simulation_valid = load_pickle(data, 'data/valid/simulation.pickle')  # 3.1 + 3.2\n",
        "simulation_test = load_pickle(data, 'data/test/simulation.pickle')  # 3.1 + 3.2\n",
        "\n",
        "\"\"\"\n",
        "charges_{train, valid, test} is stored as a list of simulation-charges. \n",
        "These charges are stored as numpy arrays of size (3,): One value for each charge.\n",
        "\"\"\"\n",
        "charges_train = load_pickle(data, 'data/train/charges.pickle')  # 3.1\n",
        "charges_valid = load_pickle(data, 'data/valid/charges.pickle')  # 3.1\n",
        "charges_test = load_pickle(data, 'data/test/charges.pickle')  # 3.1\n",
        "\n",
        "\"\"\"\n",
        "simulation_continued_{train, valid, test} is stored as a list of simulations. \n",
        "Each simulation is a numpy array of size (t, 2): For t timesteps an x and y coordinate of our particle.\n",
        "\"\"\"\n",
        "simulation_continued_train = load_pickle(data, 'data/train/simulation_continued.pickle')  # 3.2\n",
        "simulation_continued_valid = load_pickle(data, 'data/valid/simulation_continued.pickle')  # 3.2\n",
        "simulation_continued_test = load_pickle(data, 'data/test/simulation_continued.pickle')  # 3.2\n",
        "\n",
        "\"\"\"\n",
        "Note that the indices are shared throughout the different lists, e.g., for the 4th training simulation:\n",
        "simulation_train[3] contains its initial simulation\n",
        "charges_train[3] contains the charges associated with the simulation\n",
        "simulation_continued_train[3] contains the continuation of the simulation \n",
        "                --> simulation_continued_train[3][0] is the state after simulation_train[3][-1]\n",
        "\"\"\"\n",
        "pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "10a3438a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10a3438a",
        "outputId": "d5ea64ce-b88c-48d9-a788-3834f6f3f42e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overview of no. datapoints:\n",
            "\n",
            "Task 3.1:\n",
            "800 train, 100 validation, 100 test simulations\n",
            "800 train, 100 validation, 100 test charge pairs\n",
            "\n",
            "Task 3.2:\n",
            "Since len(simulation_continued_train) < len(simulation_train), we can only use a subset of initial simulations\n",
            "We cut simulation_train down to the first 150 samples in simulation_train_task32\n",
            "150 train, 100 validation, 100 test simulations\n",
            "150 train, 100 validation, 100 test continuations\n",
            "\n",
            "For task 3.1, use:\n",
            "simulation_train + charges_train\n",
            "simulation_valid + charges_valid\n",
            "simulation_test + charges_test\n",
            "\n",
            "For task 3.2, use:\n",
            "simulation_train_task32 + simulation_continued_train\n",
            "simulation_valid + simulation_continued_valid\n",
            "simulation_test + simulation_continued_test\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('Overview of no. datapoints:\\n')\n",
        "\n",
        "print('Task 3.1:')\n",
        "print(f'{len(simulation_train)} train, {len(simulation_valid)} validation, {len(simulation_test)} test simulations')\n",
        "print(f'{len(charges_train)} train, {len(charges_valid)} validation, {len(charges_test)} test charge pairs')\n",
        "print()\n",
        "\n",
        "print('Task 3.2:')\n",
        "print('Since len(simulation_continued_train) < len(simulation_train), we can only use a subset of initial simulations')\n",
        "print('We cut simulation_train down to the first 150 samples in simulation_train_task32')\n",
        "simulation_train_task32 = simulation_train[:150]\n",
        "print(f'{len(simulation_train_task32)} train, {len(simulation_valid)} validation, {len(simulation_test)} test simulations')\n",
        "print(f'{len(simulation_continued_train)} train, {len(simulation_continued_valid)} validation, {len(simulation_continued_test)} test continuations')\n",
        "\n",
        "print(f\"\"\"\n",
        "For task 3.1, use:\n",
        "{chr(10).join([\"simulation_{} + charges_{}\".format(t, t) for t in [\"train\", \"valid\", \"test\"]])}\n",
        "\n",
        "For task 3.2, use:\n",
        "{chr(10).join([\"simulation_{} + simulation_continued_{}\".format(*((t[0], t[1]) if isinstance(t, tuple) else (t, t))) for t in [(\"train_task32\", \"train\"), \"valid\", \"test\"]])}\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3cfafdb3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cfafdb3",
        "outputId": "5552fcf2-6654-4ff4-bb57-4a2c569c138c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Print some shapes:\n",
            "\n",
            "simulation_train[0].shape: (103, 2) -> (t, 2), (x, y) at every t)\n",
            "charges_train[0].shape: (3,) -> charges for the simulation\n",
            "simulation_continued_train[0].shape: (54, 2) -> (t, 2), (x, y) at every t)\n",
            "----\n",
            "\n",
            "simulation_train[1].shape: (97, 2) -> (t, 2), (x, y) at every t)\n",
            "charges_train[1].shape: (3,) -> charges for the simulation\n",
            "simulation_continued_train[1].shape: (45, 2) -> (t, 2), (x, y) at every t)\n",
            "----\n",
            "\n",
            "simulation_train[2].shape: (99, 2) -> (t, 2), (x, y) at every t)\n",
            "charges_train[2].shape: (3,) -> charges for the simulation\n",
            "simulation_continued_train[2].shape: (47, 2) -> (t, 2), (x, y) at every t)\n",
            "----\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('Print some shapes:\\n')\n",
        "for i in range(3):\n",
        "    print('simulation_train[{}].shape:'.format(i), simulation_train[i].shape, '-> (t, 2), (x, y) at every t)')\n",
        "    print('charges_train[{}].shape:'.format(i), charges_train[i].shape, '-> charges for the simulation')\n",
        "    print('simulation_continued_train[{}].shape:'.format(i), simulation_continued_train[i].shape, '-> (t, 2), (x, y) at every t)')\n",
        "    print('----\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f9106543",
      "metadata": {
        "id": "f9106543"
      },
      "outputs": [],
      "source": [
        "def plot_example(x, x_gt=None, x_pred=None, fn=None):\n",
        "    charge_locations = np.array([[-1.53846154, -1.53846154],\n",
        "                                 [ 1.53846154, -1.53846154],\n",
        "                                 [ 0.        ,  1.53846154]])  # charge locations are fixed\n",
        "    fig = plt.figure()\n",
        "    axes = plt.gca()\n",
        "    axes.set_xlim([-5., 5.])\n",
        "    axes.set_ylim([-5., 5.])\n",
        "    cmap = matplotlib.cm.get_cmap('tab20')\n",
        "    plt.plot(x[:, 0], x[:, 1], color=cmap(0))\n",
        "    plt.plot(x[0, 0], x[0, 1], 'd', color=cmap(1))\n",
        "    fig.set_size_inches(5, 5)\n",
        "    for charge in charge_locations:\n",
        "        plt.plot(charge[0], charge[1], 'd', color='black')\n",
        "    if x_gt is not None:\n",
        "        plt.plot(x_gt[:, 0], x_gt[:, 1], color='red', linewidth=.5)\n",
        "    if x_pred is not None:\n",
        "        plt.plot(x_pred[:, 0], x_pred[:, 1], color='green', linestyle='--')\n",
        "    if fn is None:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.savefig(fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d28681a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "d28681a6",
        "outputId": "4731c59e-e64b-46db-e92e-2d3a39947c96"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charges are [-0.42081992 -0.48440001 -0.65469974]\n"
          ]
        }
      ],
      "source": [
        "test_idx = np.random.randint(150)\n",
        "plot_example(simulation_train[test_idx], simulation_continued_train[test_idx])\n",
        "print(f'Charges are {charges_train[test_idx]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "883762b1",
      "metadata": {
        "id": "883762b1"
      },
      "source": [
        "# Task 3.1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c1ddabe",
      "metadata": {
        "id": "4c1ddabe"
      },
      "source": [
        "## Data Handling and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "bd9df856",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd9df856",
        "outputId": "db2c329c-7e48-4654-908d-4ea0a59a1bb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device is set to cpu\n"
          ]
        }
      ],
      "source": [
        "# Pick the best device\n",
        "import torch\n",
        "\n",
        "def try_device(device):\n",
        "    # Try to put an array on given device. If successful, return device. Else, 'cpu'.\n",
        "    x = torch.ones((1,))\n",
        "    try:\n",
        "        x.to(device)\n",
        "        return device\n",
        "    except:\n",
        "        return 'cpu'\n",
        "\n",
        "device = try_device('cuda')\n",
        "if device == 'cpu':\n",
        "    # mps doesn't support our model (yet?)\n",
        "    # device = try_device('mps')\n",
        "    pass\n",
        "\n",
        "\n",
        "print(f'Device is set to {device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7dd9b7c1",
      "metadata": {
        "id": "7dd9b7c1"
      },
      "outputs": [],
      "source": [
        "# Task 3.1: Using the positions of positively charged particle p1 during a simulation, predict the\n",
        "# values of negative charges c2, c3, c4\n",
        "# input = t locations (x, y) of p1 particle, value of t is not fixed\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pack_sequence, pad_sequence\n",
        "\n",
        "class SimulationData(Dataset):\n",
        "    def __init__(self, sim, charges):\n",
        "        self.sim = sim\n",
        "        self.charges = charges\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sim)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.sim[idx], self.charges[idx]\n",
        "\n",
        "# Create data loader\n",
        "def cpu_collate(data):\n",
        "    # Sort data in order of decreasing sequence length\n",
        "    data = list(reversed(sorted(data, key=lambda d: len(d[0]))))\n",
        "    xs = pad_sequence([torch.tensor(x).float() for x, _ in data], batch_first=True)\n",
        "    ys = torch.stack([torch.tensor(y).float() for _, y in data])\n",
        "    return xs, ys\n",
        "\n",
        "\n",
        "# Create data loader\n",
        "def gpu_collate(data):\n",
        "    # Sort data in order of decreasing sequence length\n",
        "    data = list(reversed(sorted(data, key=lambda d: len(d[0]))))\n",
        "    xs = pad_sequence([torch.tensor(x).float() for x, _ in data], batch_first=True)\n",
        "    ys = torch.stack([torch.tensor(y).float() for _, y in data])\n",
        "    return xs.to(device), ys.to(device)\n",
        "\n",
        "\n",
        "# Batch size needs to evenly divide all train, valid, test sizes (800, 100, 100)\n",
        "batch_size = 5\n",
        "cpu_train_dl = DataLoader(SimulationData(simulation_train, charges_train), batch_size=batch_size, shuffle=True, collate_fn=cpu_collate)\n",
        "cpu_valid_dl = DataLoader(SimulationData(simulation_valid, charges_valid), batch_size=batch_size, shuffle=True, collate_fn=cpu_collate)\n",
        "\n",
        "gpu_train_dl = DataLoader(SimulationData(simulation_train, charges_train), batch_size=batch_size, shuffle=True, collate_fn=gpu_collate)\n",
        "gpu_valid_dl = DataLoader(SimulationData(simulation_valid, charges_valid), batch_size=batch_size, shuffle=True, collate_fn=gpu_collate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4ec1e03a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ec1e03a",
        "outputId": "11f3e001-958d-4938-ea2e-66202292f1af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(103, 2)\n",
            "5\n",
            "torch.Size([107, 2]) torch.Size([3])\n"
          ]
        }
      ],
      "source": [
        "print(simulation_train[0].shape)\n",
        "# Test data loader\n",
        "xs, ys = next(iter(cpu_train_dl))\n",
        "print(len(xs))\n",
        "print(xs[0].shape, ys[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "d48b8fb1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d48b8fb1",
        "outputId": "a732a865-bd74-4fdd-88d2-14eaf5817f6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline L1 train error: 0.7429320812225342\n",
            "Baseline L1 validation error: 0.7968490719795227\n"
          ]
        }
      ],
      "source": [
        "# Baseline model: predict the mean value of each charge in the training set\n",
        "baseline_values = torch.tensor(np.array(charges_train).mean(axis=0))\n",
        "def baseline_predict(xs):\n",
        "    batch = xs.shape[0]\n",
        "    return baseline_values.expand(batch, 3)\n",
        "\n",
        "loss_fn = lambda y, y_pred: (y - y_pred).abs().sum()\n",
        "\n",
        "# Baseline error?\n",
        "\n",
        "def avg_err(model, dl, loss_fn=torch.nn.L1Loss(reduction='sum')):\n",
        "    loss = 0\n",
        "    n_samples = 0\n",
        "    for x, y in dl:\n",
        "        y_pred = model(x)\n",
        "        loss += loss_fn(y, y_pred)\n",
        "        n_samples += x.shape[0]\n",
        "    return loss / n_samples\n",
        "\n",
        "\n",
        "print(f'Baseline L1 train error: {avg_err(baseline_predict, cpu_train_dl)}')\n",
        "print(f'Baseline L1 validation error: {avg_err(baseline_predict, cpu_valid_dl)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc8853f6",
      "metadata": {
        "id": "cc8853f6"
      },
      "source": [
        "## Model Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8794a0cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8794a0cf",
        "outputId": "6a243bef-aef6-4232-9049-6604a6e94819"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 3])\n"
          ]
        }
      ],
      "source": [
        "class Model_3_1(torch.nn.Module):\n",
        "    def __init__(self, hidden_dim, n_layers, batch_size):\n",
        "        super(Model_3_1, self).__init__()\n",
        "        # input/output size are fixed based on the task description\n",
        "        input_dim = 2\n",
        "        output_dim = 3\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.batch_size = batch_size\n",
        "        \n",
        "        self.gru = torch.nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = self.init_hidden()\n",
        "        x = x.to(device)\n",
        "        out, h = self.gru(x, h)\n",
        "        out = self.fc(self.relu(out[:,-1]))\n",
        "        return out\n",
        "    \n",
        "    def init_hidden(self):\n",
        "        # from example of https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\n",
        "        h0 = torch.randn(self.n_layers, self.batch_size, self.hidden_dim).to(device)\n",
        "        return h0\n",
        "\n",
        "xs = xs.to(device)\n",
        "model_3_1 = Model_3_1(30, 5, batch_size).to(device)\n",
        "print(model_3_1(xs).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e443b7f",
      "metadata": {
        "id": "0e443b7f"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "5a5b0aca",
      "metadata": {
        "id": "5a5b0aca"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "train_loss_graph, val_loss_graph = list(), list()\n",
        "\n",
        "def fit_3_1(model, train_dl, valid_dl, n_epochs):\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
        "    loss_func = torch.nn.L1Loss()\n",
        "    loss_func = loss_func.to(device)\n",
        "\n",
        "    for i in range(n_epochs):\n",
        "        print(f'Begin epoch {i + 1}/{n_epochs}')\n",
        "        for x, y in tqdm(train_dl):\n",
        "            x = x.to(device)\n",
        "            y = y.to(device).float()\n",
        "            y_pred = model(x)\n",
        "            loss = loss_func(y, y_pred)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            train_err = avg_err(model, train_dl)\n",
        "            val_err = avg_err(model, valid_dl)\n",
        "            print(f'L1 train error: {train_err}')\n",
        "            print(f'L1 validation error: {val_err}')\n",
        "            train_loss_graph.append(train_err)\n",
        "            val_loss_graph.append(val_err)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "a3181fdc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3181fdc",
        "outputId": "b28ca57b-6209-4987-a818-15214ba7a353"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model has 25473 parameters\n",
            "Begin epoch 1/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 160/160 [00:20<00:00,  7.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1 train error: 0.6599063277244568\n",
            "L1 validation error: 0.7203518152236938\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "hidden_size = 30\n",
        "n_layers = 5\n",
        "model_3_1 = Model_3_1(hidden_size, n_layers, batch_size).to(device)\n",
        "print(f'Model has {count_parameters(model_3_1)} parameters')\n",
        "epochs = 1\n",
        "fit_3_1(model_3_1, gpu_train_dl, gpu_valid_dl, epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "cd0abda7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "cd0abda7",
        "outputId": "d514f2ed-29f9-4117-cfc5-f75f881f6806"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss value')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_loss_graph_cpu = [i.to(device='cpu') for i in train_loss_graph]\n",
        "\n",
        "plt.plot(train_loss_graph_cpu)\n",
        "plt.title(\"training loss\")\n",
        "plt.xlabel(\"epoch number\")\n",
        "plt.ylabel(\"loss value\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "5af330cd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "5af330cd",
        "outputId": "016fad87-6a0c-4862-f236-c137abaaca17"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss value')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "val_loss_graph_cpu = [i.to(device='cpu') for i in val_loss_graph]\n",
        "\n",
        "plt.plot(val_loss_graph_cpu)\n",
        "plt.title(\"validation loss\")\n",
        "plt.xlabel(\"epoch number\")\n",
        "plt.ylabel(\"loss value\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da139d5b",
      "metadata": {
        "id": "da139d5b"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "ebed03ba",
      "metadata": {
        "id": "ebed03ba"
      },
      "outputs": [],
      "source": [
        "#todo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "17af7ec3",
      "metadata": {
        "id": "17af7ec3"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "43a3422e",
      "metadata": {
        "id": "43a3422e"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a59808b",
      "metadata": {
        "id": "9a59808b"
      },
      "source": [
        "# Task 3.2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f64a855d",
      "metadata": {
        "id": "f64a855d"
      },
      "source": [
        "## Data Handling and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "5b935865",
      "metadata": {
        "id": "5b935865"
      },
      "outputs": [],
      "source": [
        "#todo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "0ec19a8d",
      "metadata": {
        "id": "0ec19a8d"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "8f189d19",
      "metadata": {
        "id": "8f189d19"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "867aabb3",
      "metadata": {
        "id": "867aabb3"
      },
      "source": [
        "## Model Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "fb3f2e03",
      "metadata": {
        "id": "fb3f2e03"
      },
      "outputs": [],
      "source": [
        "x_train_shapes = [np.array(simulation_train_task32, dtype=object)[i].shape[0] for i in range(len(simulation_train_task32))]\n",
        "y_train_shapes = [np.array(simulation_continued_train, dtype=object)[i].shape[0] for i in range(len(simulation_continued_train))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "d536e656",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d536e656",
        "outputId": "4b0eb406-b119-47ae-e336-208e863d0420"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training x | Mean: 99.49333333333334, Std: 6.2841034010871875, Min: 90, Max: 110\n",
            "Training y | Mean: 41.026666666666664, Std: 12.265913020326789, Min: 20, Max: 60\n"
          ]
        }
      ],
      "source": [
        "print(f\"Training x | Mean: {np.array(x_train_shapes).mean()}, Std: {np.array(x_train_shapes).std()}, Min: {np.array(x_train_shapes).min()}, Max: {np.array(x_train_shapes).max()}\")\n",
        "print(f\"Training y | Mean: {np.array(y_train_shapes).mean()}, Std: {np.array(y_train_shapes).std()}, Min: {np.array(y_train_shapes).min()}, Max: {np.array(y_train_shapes).max()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "ebd6f052",
      "metadata": {
        "id": "ebd6f052"
      },
      "outputs": [],
      "source": [
        "# Task 3.2: Using the positions of positively charged particle p1 during a simulation up to t=10 +- 1,\n",
        "# continue its trajectory for an additional 4 +- 2 seconds.\n",
        "# input = t locations (x, y) of p1 particle, value of t is not fixed\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pack_sequence, pad_sequence\n",
        "\n",
        "\n",
        "global zero_x\n",
        "zero_x = torch.zeros((110, 2))\n",
        "global zero_y\n",
        "zero_y = torch.zeros((60, 2))\n",
        "\n",
        "\n",
        "class loadContinued(Dataset):\n",
        "    def __init__(self, sim, cont_positions):\n",
        "        self.sim = sim\n",
        "        self.cont_positions = cont_positions\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.sim)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        return torch.tensor(self.sim[index]).float(), torch.tensor(self.cont_positions[index]).float()\n",
        "\n",
        "\n",
        "# No batch size since the length of y differs for each simulation.\n",
        "gpu_cont_train_dl = DataLoader(loadContinued(simulation_train_task32, simulation_continued_train), shuffle=True)\n",
        "gpu_cont_valid_dl = DataLoader(loadContinued(simulation_valid, simulation_continued_valid), shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline model and evaluation"
      ],
      "metadata": {
        "id": "6GerDoOL9f-m"
      },
      "id": "6GerDoOL9f-m"
    },
    {
      "cell_type": "code",
      "source": [
        "class linearRegression(torch.nn.Module):\n",
        "    def __init__(self, inputSize, outputSize):\n",
        "        super(linearRegression, self).__init__()\n",
        "        self.linear = torch.nn.Linear(inputSize, outputSize)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        return out\n",
        "input_size = 2\n",
        "output_size = 2\n",
        "basemodel = linearRegression(input_size, output_size)"
      ],
      "metadata": {
        "id": "XgQv30Ugb2AO"
      },
      "id": "XgQv30Ugb2AO",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_fit(model, train_dl, valid_dl):\n",
        "    train_loss_graph, val_loss_graph = list(), list()\n",
        "    lr = 1e-4\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "    loss_func = torch.nn.L1Loss()\n",
        "    loss_func = loss_func.to(device)\n",
        "\n",
        "    model = model.train()\n",
        "    for i in tqdm(range(10)):\n",
        "        train_loss, val_loss = list(), list()\n",
        "        for x, y in train_dl:\n",
        "            # Squeeze away the batch size of 1\n",
        "            x = x.squeeze(0)\n",
        "            y = y.squeeze(0)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(x[0])\n",
        "\n",
        "            loss = loss_func(outputs, x[1])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss.append(loss.item())\n",
        "\n",
        "        train_loss_graph.append(sum(train_loss) / len(train_dl))\n",
        "\n",
        "        model = model.eval()\n",
        "        with torch.no_grad():\n",
        "            for x_val, y_val in valid_dl:\n",
        "                # Squeeze away the batch size of 1\n",
        "                x_val = x_val.squeeze(0)\n",
        "                y_val = y_val.squeeze(0)\n",
        "                outputs_val = model(x_val[0])\n",
        "                \n",
        "                y_val = y_val.squeeze(1)\n",
        "                loss_val = loss_func(outputs_val, x_val[1])\n",
        "                \n",
        "                val_loss.append(loss_val.item())\n",
        "                torch.cuda.empty_cache()\n",
        "            \n",
        "        val_loss_graph.append(sum(val_loss) / len(valid_dl))\n",
        "\n",
        "    return {'train': sum(train_loss_graph)/len(train_loss_graph), 'valid': sum(val_loss_graph)/len(val_loss_graph)}\n"
      ],
      "metadata": {
        "id": "z_j4donT83m9"
      },
      "id": "z_j4donT83m9",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_train_dl = DataLoader(loadContinued(simulation_train_task32[-10:], simulation_continued_train), shuffle=True)\n",
        "base_valid_dl = DataLoader(loadContinued(simulation_valid, simulation_continued_valid), shuffle=True)\n",
        "x,y = next(iter(base_train_dl))\n",
        "x.shape,y.shape\n",
        "#baseline_fit(basemodel,gpu_cont_train_dl,gpu_cont_valid_dl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neVjemFvxeQE",
        "outputId": "d0efcd0b-1c66-4d35-fb4f-35ae90016050"
      },
      "id": "neVjemFvxeQE",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 91, 2]), torch.Size([1, 58, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_fit(basemodel,base_train_dl,base_valid_dl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXgGNYlK0yYG",
        "outputId": "bfca4f17-af76-4b43-9ce6-f986b3ec37d4"
      },
      "id": "tXgGNYlK0yYG",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 36.89it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': 0.9738261312246322, 'valid': 1.0652202953100205}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "bfb20065",
      "metadata": {
        "id": "bfb20065"
      },
      "outputs": [],
      "source": [
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "fec35415",
      "metadata": {
        "id": "fec35415"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, n_layers, dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.input_size = input_size\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.gru = torch.nn.GRU(input_size, hidden_size, n_layers, dropout=dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        hidden = self.init_hidden()\n",
        "        output, hidden = self.gru(x, hidden)\n",
        "        \n",
        "        return output, hidden\n",
        "    \n",
        "    def init_hidden(self):\n",
        "        h0 = torch.zeros(self.n_layers, self.hidden_size).to(device)\n",
        "        return h0\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "165034ab",
      "metadata": {
        "id": "165034ab"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_size, n_layers, dropout):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.gru = nn.GRU(input_size, hidden_size, n_layers, dropout=dropout)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        \n",
        "    def forward(self, x, hidden):\n",
        "        output, hidden = self.gru(x, hidden)\n",
        "        output = self.out(output)\n",
        "        \n",
        "        return output, hidden\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "5d6041e8",
      "metadata": {
        "id": "5d6041e8"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "criterion = torch.nn.L1Loss()\n",
        "\n",
        "\n",
        "def fit_seq(encoder_model, decoder_model, train_dl, valid_dl, n_epochs, teacher_forcing_ratio):\n",
        "    train_loss_graph, val_loss_graph = list(), list()\n",
        "    lr = 1e-4\n",
        "    encoder_optimizer = torch.optim.AdamW(encoder_model.parameters(), lr=lr)\n",
        "    decoder_optimizer = torch.optim.AdamW(decoder_model.parameters(), lr=lr)\n",
        "    loss_func = torch.nn.L1Loss()\n",
        "    loss_func = loss_func.to(device)\n",
        "\n",
        "    for i in tqdm(range(epochs)):\n",
        "        train_loss, val_loss = list(), list()\n",
        "        \n",
        "        encoder_model = encoder_model.train()\n",
        "        decoder_model = decoder_model.train()\n",
        "        for x, y in train_dl:\n",
        "            # Squeeze away the batch size of 1\n",
        "            x = x.squeeze(0)\n",
        "            y = y.squeeze(0)\n",
        "            encoder_optimizer.zero_grad()\n",
        "            decoder_optimizer.zero_grad()\n",
        "            \n",
        "            encoder_output, hidden = encoder_model(x)\n",
        "            outputs = torch.zeros(y.shape[0], 2).to(device)\n",
        "            \n",
        "            # The initial input to the decoder is the last input position\n",
        "            input_decoder = x[-1].unsqueeze(0)\n",
        "            for inx, y_i in enumerate(y):\n",
        "                output, hidden = decoder_model(input_decoder, hidden)\n",
        "                \n",
        "                outputs[inx] = output\n",
        "                \n",
        "                teacher_force = random.random() < teacher_forcing_ratio\n",
        "                input_decoder = y_i if teacher_force else output\n",
        "            \n",
        "            y = y.squeeze(1)\n",
        "            loss = loss_func(outputs, y)\n",
        "            loss.backward()\n",
        "            \n",
        "            encoder_optimizer.step()\n",
        "            decoder_optimizer.step()\n",
        "            \n",
        "            train_loss.append(loss.item())            \n",
        "            torch.cuda.empty_cache()\n",
        "        \n",
        "        train_loss_graph.append(sum(train_loss) / len(train_dl))\n",
        "        \n",
        "        encoder_model = encoder_model.eval()\n",
        "        decoder_model = decoder_model.eval()\n",
        "        with torch.no_grad():\n",
        "            for x_val, y_val in valid_dl:\n",
        "                # Squeeze away the batch size of 1\n",
        "                x_val = x_val.squeeze(0)\n",
        "                y_val = y_val.squeeze(0)\n",
        "                encoder_output, hidden = encoder_model(x_val.squeeze(1))\n",
        "                outputs_val = torch.zeros(y_val.shape[0], 2).to(device)\n",
        "                \n",
        "                input_decoder = x_val[-1].unsqueeze(0)\n",
        "                for inx, y_i in enumerate(y_val):\n",
        "                    output, hidden = decoder_model(input_decoder, hidden)\n",
        "                    \n",
        "                    outputs_val[inx] = output\n",
        "                    \n",
        "                    input_decoder = output\n",
        "                \n",
        "                y_val = y_val.squeeze(1)\n",
        "                loss_val = loss_func(outputs_val, y_val)\n",
        "                \n",
        "                val_loss.append(loss_val.item())\n",
        "                torch.cuda.empty_cache()\n",
        "            \n",
        "        val_loss_graph.append(sum(val_loss) / len(valid_dl))\n",
        "\n",
        "    return {'train': train_loss_graph, 'valid': val_loss_graph}\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "5a455c3e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "5a455c3e",
        "outputId": "b680036c-cdc6-43cb-cf14-036ffb8ae2ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder Model has 87936 parameters\n",
            "Decoder Model has 88066 parameters\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 10/200 [05:18<1:40:47, 31.83s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-31af818fedce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m                  \u001b[0mvalid_dl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgpu_cont_valid_dl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                  \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                  teacher_forcing_ratio=0.0)\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mencoder_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mdecoder_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-089abaeb00eb>\u001b[0m in \u001b[0;36mfit_seq\u001b[0;34m(encoder_model, decoder_model, train_dl, valid_dl, n_epochs, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0minput_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0minx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-be3bbb538098>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0mbatch_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_batched\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "n_layers = 4\n",
        "dropout = 0.5\n",
        "input_size = 2\n",
        "output_size = 2\n",
        "hidden_size = 64\n",
        "\n",
        "encoder_model = Encoder(input_size, hidden_size, n_layers, dropout).to(device)\n",
        "decoder_model = Decoder(input_size, output_size, hidden_size, n_layers, dropout).to(device)\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'Encoder Model has {count_parameters(encoder_model)} parameters')\n",
        "print(f'Decoder Model has {count_parameters(decoder_model)} parameters')\n",
        "epochs = 200\n",
        "result = fit_seq(encoder_model=encoder_model,\n",
        "                 decoder_model=decoder_model,\n",
        "                 train_dl=gpu_cont_train_dl, \n",
        "                 valid_dl=gpu_cont_valid_dl, \n",
        "                 n_epochs=epochs, \n",
        "                 teacher_forcing_ratio=0.0)\n",
        "encoder_model = encoder_model.eval()\n",
        "decoder_model = decoder_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "380b42aa",
      "metadata": {
        "id": "380b42aa"
      },
      "outputs": [],
      "source": [
        "plt.plot(np.arange(1, epochs + 1), result['valid'], label='valid')\n",
        "plt.plot(np.arange(1, epochs + 1), result['train'], label='train')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(f'Min train loss was {min(result[\"train\"])}')\n",
        "print(f'Min validation loss was {min(result[\"valid\"])}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75b49452",
      "metadata": {
        "id": "75b49452"
      },
      "outputs": [],
      "source": [
        "x, y = next(iter(gpu_cont_valid_dl))\n",
        "\n",
        "x = x.squeeze(0)\n",
        "y = y.squeeze(0)\n",
        "encoder_output, hidden = encoder_model(x)\n",
        "outputs = torch.zeros(y.shape[0], 2).to(device)\n",
        "\n",
        "input_decoder = x[-1].unsqueeze(0)\n",
        "for inx, y_i in enumerate(y):\n",
        "    output, hidden = decoder_model(input_decoder, hidden)\n",
        "\n",
        "    outputs[inx] = output\n",
        "\n",
        "    input_decoder = output\n",
        "\n",
        "x = x.to(device='cpu').detach().numpy()\n",
        "new_y_pred = outputs.to(device='cpu').detach().numpy()\n",
        "    \n",
        "print(x.shape, y.shape, outputs.shape)\n",
        "print(f'loss value: {criterion(y.squeeze(1), outputs).item()}')\n",
        "plot_example(x, x_gt=y.squeeze(1), x_pred=np.array(new_y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d29b6790",
      "metadata": {
        "id": "d29b6790"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bf231ea",
      "metadata": {
        "id": "4bf231ea"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f458b614",
      "metadata": {
        "id": "f458b614"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "27c164e33ceb3372f7d05cab3554d1b7111f26924d32637c2cc5dd0d753ab5f1"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "name": "a3_skeleton_peter-pim-peter.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}