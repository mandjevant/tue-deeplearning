{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "JiwpncEfEQ6w",
   "metadata": {
    "id": "JiwpncEfEQ6w"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/vlamen/tue-deeplearning/blob/main/practicals/P4.2_Graph_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XZBHIfDJveSN",
   "metadata": {
    "id": "XZBHIfDJveSN"
   },
   "source": [
    "# P4.2: Graph Classification (using Graph Neural Networks)\n",
    "In this practical we will apply Graph Neural Networks (GNNs) to the task of classifying entire graphs. We will use PyTorch and the PyTorch Geometric library [[1]](#pytorchgeomintro).\n",
    "\n",
    "Upon completing this practical, you will have:\n",
    "\n",
    "*   Studied a hands-on introduction to the graph classification problem;\n",
    "*   Enhanced your understanding of Graph Neural Networks by implementing a message passing GNN (as described in the lecture notes) from scratch in PyTorch;\n",
    "*   Learned how to use the PyTorch Geometric library for minibatching graphs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9oo1kU_Qjb",
   "metadata": {
    "id": "cc9oo1kU_Qjb"
   },
   "source": [
    "# Preparation\n",
    "To start, we install the packages we need, set up some formatting for the notebook, and download the data we use in this practical. If necessary, uncomment and run the cell below to install the required packages (for example if you're using google colab)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "djyRhMjVChaz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "djyRhMjVChaz",
    "outputId": "c4438934-8cf0-4521-865e-e5f459f720ed"
   },
   "outputs": [],
   "source": [
    "# # PyTorch Geometric is not part of the standard Colab packages, we must install it ourselves\n",
    "# !pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
    "# !pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
    "# !pip install -q torch-geometric\n",
    "\n",
    "\n",
    "#!pip install decorator==5.0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TmqpM9AyDGkj",
   "metadata": {
    "id": "TmqpM9AyDGkj"
   },
   "outputs": [],
   "source": [
    "# # We want to limit the height of the output cells.\n",
    "from IPython.display import HTML, display, Javascript\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bda20d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "22bda20d",
    "outputId": "0a656e53-5d54-4eca-8a60-b4b22217dbc6"
   },
   "outputs": [],
   "source": [
    "# We will use the Mutagenicity dataset, which is part of the standard datasets in torch geometric.\n",
    "# downloading may take some time\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import numpy as np\n",
    "dataset = TUDataset(root='data/mutagen', name='Mutagenicity', use_node_attr=True, use_edge_attr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a84ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the below list and dict maps an integer to the corresponiding element string and an element string to a color respectively.\n",
    "# this will be useful for plotting molecules later on\n",
    "\n",
    "element_map = ['C', 'O', 'Cl', 'H', 'N', 'F', 'Br', 'S', 'P', 'I', 'Na', 'K', 'Li', 'Ca']\n",
    "element_color = {\n",
    "    'H': [1.0, 1.0, 1.0],\n",
    " 'Li': [0.8, 0.5019607843137255, 1.0],\n",
    " 'C': [0.5647058823529412, 0.5647058823529412, 0.5647058823529412],\n",
    " 'N': [0.18823529411764706, 0.3137254901960784, 0.9725490196078431],\n",
    " 'O': [1.0, 0.050980392156862744, 0.050980392156862744],\n",
    " 'F': [0.5647058823529412, 0.8784313725490196, 0.3137254901960784],\n",
    " 'Na': [0.6705882352941176, 0.3607843137254902, 0.9490196078431372],\n",
    " 'P': [1.0, 0.5019607843137255, 0.0],\n",
    " 'S': [1.0, 1.0, 0.18823529411764706],\n",
    " 'Cl': [0.12156862745098039, 0.9411764705882353, 0.12156862745098039],\n",
    " 'K': [0.5607843137254902, 0.25098039215686274, 0.8313725490196079],\n",
    " 'Ca': [0.23921568627450981, 1.0, 0.0],\n",
    "'Br': [0.6509803921568628, 0.1607843137254902, 0.1607843137254902],\n",
    " 'I': [0.5803921568627451, 0.0, 0.5803921568627451]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UUy-_h3cAW_N",
   "metadata": {
    "id": "UUy-_h3cAW_N"
   },
   "source": [
    "# Problem Formulation\n",
    "The type of data we consider is graph data, where a graph is defined by its nodes and edges, $\\mathcal{G} = (\\mathcal{V},\\mathcal{E})$. The dataset consists of many (comparatively small) graphs, and we seek to classify these graphs in their entirety. As such, in this practical, a *graph* is analogous to an image in an image classification task (as opposed to the earlier tutorial, where we tried to classify each *node* in a graph).\n",
    "\n",
    "We can define our data $X$ as a set of graphs, i.e., $X = \\{\\mathcal{G}_0, \\mathcal{G}_1, \\ldots, \\mathcal{G}_n\\}$, wich corresponding labels $\\{Y_0, Y_1, \\ldots, Y_n\\}$.\n",
    "\n",
    "## Dataset: Database of molecules and their mutagenicity\n",
    "The dataset we look at for this practical consists of molecules and their mutagenicity property[[2]](#mutagenicity). This property describes whether a molecule can induce genetic mutations or not, making it a binary attribute. \n",
    "\n",
    "The datapoints in the dataset are molecular graphs $\\mathcal{G}_i \\in X$, and each such molecule-graph is assigned a label 0 (no mutagenicity) or 1 (mutagenicity). The nodes in the molecule-graph indicate (chemical) elements, whereas edges indicate connections between these elements.\n",
    "\n",
    "We want to train a GNN to take these graphs as input and output a prediction. Note that there are no constraints on these graphs in terms of size or connections, and consequently our model must be able to process arbitrary graphs. This is where the use of GNNs shines, as this class of NN-models can process graphs of arbitrary shape.\n",
    "\n",
    "Next, we will further examine our dataset and split it into a train and validation set; note that for this practical, we don't use a test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_peXi7DIfAbG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "_peXi7DIfAbG",
    "outputId": "95fea4fe-645c-4613-db97-c17fd6c1e0cb"
   },
   "outputs": [],
   "source": [
    "print(f'Number of examples: {len(dataset)}')\n",
    "print('')\n",
    "print(\"Let's print a few examples' shape:\")\n",
    "for i in range(4):\n",
    "    print(dataset[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kS1M89qFfr4s",
   "metadata": {
    "id": "kS1M89qFfr4s"
   },
   "source": [
    "The dataset consists of 4337 molecules. As we can see from printing a few examples, they vary in shape. As a reminder of what these tensors are, for an arbitrary graph $\\mathcal{G}$:\n",
    "\n",
    "$edge\\_attr=[\\mathcal{G}_\\mathcal{E}, \\mathcal{E}_a]$: Edge attributes, for each edge $\\mathcal{E}$ in graph $\\mathcal{G}$, we have $\\mathcal{E}_a$ attributes. For simplicity, we do not use these attributes in this notebook, but once you have a GNN architecture set up, it should be straightforward to incorporate edge features as well.\n",
    "\n",
    "$edge\\_index=[2, \\mathcal{G}_\\mathcal{E}]$: The tensor describing all edges in the graph. The first row describes the source node of each edge, whereas the second row describes the target node of each edge. E.g., $edge\\_index=[[0, 1, 2], [3, 4, 5]]$ describes edges $(0, 3), (1, 4)$ and $(2, 5)$. For undirected graphs (as in this practical), we assume that the edge index contains both $(i ,j)$ and $(j,i)$ for all connected nodes $i, j$.\n",
    "\n",
    "$x=[\\mathcal{G}_\\mathcal{V}, \\mathcal{V}_a]$: The tensor describing all nodes and their attributes. For each node $\\mathcal{V}$ in graph $\\mathcal{G}$, we have $\\mathcal{V}_a$ attributes.\n",
    "\n",
    "$y=[1]$: The (binary) label for the graph.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CPAl4NJGhzXh",
   "metadata": {
    "id": "CPAl4NJGhzXh"
   },
   "source": [
    "The number of nodes and edges ($\\mathcal{G}_\\mathcal{V}$ and $\\mathcal{G}_\\mathcal{E}$) can differ for each graph, whereas the node and edge attributes ($\\mathcal{V}_a$ and $\\mathcal{E}_a$) are fixed for the entire dataset. As stated before, we do not use the edge attributes in this practical. The node attributes *are* used. Each node has a one-hot vector that indicates what element the node is. The following 14 elements are used in this dataset:\n",
    "```\n",
    "['C', 'O', 'Cl', 'H', 'N', 'F', 'Br', 'S', 'P', 'I', 'Na', 'K', 'Li', 'Ca']\n",
    "```\n",
    "For each node, the attribute is a one-hot encoding with the index of the 1 indicating what element it is, according to the list printed above.\n",
    "\n",
    "We aim to use these node attributes ($x$) along with their connections ($edge\\_index$) to predict the mutagenicity of the molecule ($y$). To get an idea of what a single datapoint looks like, we define a function to draw one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1964036f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "1964036f",
    "outputId": "223a40e1-9318-446d-d6a7-397d40d8ce42"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_molecule(graph, title=''):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    nodes = {}  # create a node dict (idx:element) to create a nx graph\n",
    "    for i in range(graph.x.shape[0]):\n",
    "        element_idx = np.argmax(graph.x[i])\n",
    "        nodes[i] = element_map[element_idx]\n",
    "    edges = []  # create an edge list for the nx graph\n",
    "    for i in range(graph.edge_index.shape[1]):\n",
    "        s, t = graph.edge_index[:, [i]]\n",
    "        s, t = int(s), int(t)\n",
    "        edges.append((s, t))\n",
    "\n",
    "    g = nx.Graph()  # create a graph\n",
    "    g.add_nodes_from(nodes)\n",
    "    g.add_edges_from(edges) \n",
    "    \n",
    "    pos = nx.planar_layout(g)  # the graph has no 'position': generate a node-layout\n",
    "    pos = nx.spring_layout(g, pos=pos)\n",
    "\n",
    "    colors = [element_color[i] for _, i in nodes.items()]  # set the color for each node\n",
    "    nx.draw(g, pos=pos, labels=nodes, node_color=colors, width=1)  # and draw the graph\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    ax.collections[0].set_edgecolor(\"#000000\")  # color the edges\n",
    "    \n",
    "    display(HTML(\"\"\"<style>#output-body {display: flex;align-items: center;justify-content: center;}</style>\"\"\"))  # center the image\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7acb62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "dc7acb62",
    "outputId": "6dad8e1a-439f-46f9-8e8a-601f8236b128"
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "draw_molecule(dataset[idx], f'Sample {idx}, Mutagenicity = {bool(dataset[idx].y)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Wl13S34gkjvE",
   "metadata": {
    "id": "Wl13S34gkjvE"
   },
   "source": [
    "Note that the location / layout of the nodes is somewhat arbitrary, and is generated by our drawing function. The graph information we have only considers the nodes' element, alongside what other nodes they are connected to. There are no 'coordinates' available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kVafXLUnlJQ-",
   "metadata": {
    "id": "kVafXLUnlJQ-"
   },
   "source": [
    "Next, we will split our dataset into a train and validation set and define a dataloader. The latter allows us to process graphs in minibatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p_xlCEMvAAw1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "p_xlCEMvAAw1",
    "outputId": "82b8dd49-57ad-4644-b224-51bf80c527d9"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "We simply shuffle and split the dataset to create a train and validation set.\n",
    "'''\n",
    "dataset.shuffle() # first, shuffle our dataset\n",
    "train_idx = round(len(dataset) * 0.8) # 80:20 for the train:validation split\n",
    "dataset_train = dataset[:train_idx]\n",
    "dataset_val = dataset[train_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97691e3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "d97691e3",
    "outputId": "fb45418e-ce88-449d-9e0c-93722c288a7d"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "To process the dataset in minibatches, we use a DataLoader object. All we must do\n",
    "is supply the data and set the batch_size, PyTorch Geometric will take care of the rest.\n",
    "Note that the batch_size indicates the number of graphs in a batch, not the number of nodes.\n",
    "'''\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset_val, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Zdbbb1sqptX1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Zdbbb1sqptX1",
    "outputId": "25fe4542-2cd5-4610-a3f0-c048cb4e9891"
   },
   "outputs": [],
   "source": [
    "# To understand how graphs are batched, print one\n",
    "for data in train_loader:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "azAAam4rp0IP",
   "metadata": {
    "id": "azAAam4rp0IP"
   },
   "source": [
    "Minibatching with graphs is slightly trickier than with structured inputs, as each graph consists of different amounts of nodes and edges, and PyTorch requires all tensors in the batch to be of the same size. In short, to efficiently process all nodes in a batch, PyTorch Geometric concatenates all node/edge data for all graphs in the batch to a single graph object, where each individual graph is a disconnected component (which explains the singular and large $x$/$edge\\_index$, etc). In computer memory, this graph is represented as a single tensor, allowing more efficient processing on the GPU. To be able to identify to which individual graph a node belongs, a $batch$ tensor maps each node to the graph it belongs to. For more information, we refer to the [documentation](https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html#mini-batches)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QRYLDURxAwJS",
   "metadata": {
    "id": "QRYLDURxAwJS"
   },
   "source": [
    "# TODO: Implement Graph Classification Model\n",
    "Now that we have discussed the problem and dataset, we can move towards a solution to the problem. Although PyTorch Geometric already implements many common GNN architectures, the goal of this practical is to deepen your understanding by implementing a GNN from scratch in PyTorch. This will also help you in assignments or future projects where off-the-shelf GNN architectures may be suboptimal.\n",
    "\n",
    "In the below cells, we provide some imports that will come in handy, as well as a few skeleton classes that can help you to structure your implementation.\n",
    "\n",
    "An accuracy of 75-80% on the validation set should be achievable with a relatively simple network (not too many layers) and without too much parameter tuning, within 100 training epochs. Depending on your implementation, you can expect the training of the model to take at most 10 minutes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1493c6e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "1493c6e5",
    "outputId": "e0365ff4-a07e-400b-fda8-01074554e3a7"
   },
   "outputs": [],
   "source": [
    "num_features = int(dataset_train[0].x.shape[1])\n",
    "num_classes = int(max([d.y for d in dataset_train])+1)\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OWFeY_tDmlnn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "OWFeY_tDmlnn",
    "outputId": "cca5c962-7d76-4f7e-9eb2-0e16d2469e42"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO: Implement a message passing GNN.\n",
    "Hint: you might want to look into torch.Tensor.scatter_add_() or similar functions for aggregating tensors at specified indices.\n",
    "\"\"\"\n",
    "\n",
    "class Node_to_emb(nn.Module):  # transforms input nodes to an embedding (similar to word embedding in NLP)\n",
    "\n",
    "    def __init__(self, ...):\n",
    "        super().__init__()\n",
    "        #  TODO: initialize the layers you want to use in this class.\n",
    "        pass\n",
    "\n",
    "    def forward(self, nodes):\n",
    "        #  TODO: call the layers in the forward pass.\n",
    "        pass\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "class MpLayer(torch.nn.Module):  # a neural message passing layer\n",
    "    def __init__(self, ...):\n",
    "        super().__init__()\n",
    "        \n",
    "        #  TODO: initialize the layers you want to use in this class.\n",
    "        #  Hint: which neural networks are used in neural message passing?\n",
    "        pass\n",
    "\n",
    "        \n",
    "    def forward(self, input_to_layer):\n",
    "        \n",
    "        #  TODO: call the layers in the forward pass. Be sure to use an aggregation function that is invariant to permutations\n",
    "        #        (such as summation, maximum, ...). Return the node embeddings after this message passing iteration.\n",
    "        \n",
    "        # Hint: the input_to_layer should consist of the node feature tensors and edge index tensors:\n",
    "        node_tensor, edge_idx_tensor = input_to_layer\n",
    "\n",
    "        pass\n",
    "        \n",
    "        \n",
    "\n",
    "class MpGNN(torch.nn.Module): # a message passing GNN\n",
    "    def __init__(self, ...):\n",
    "        super().__init__()\n",
    "        \n",
    "        #  TODO: initialize the layers you want to use in this class.\n",
    "        \n",
    "        #  Hint: the MpGNN must embed the categorical node features, apply message passing layers,\n",
    "        #        and finally predict the mutagenicity of each graph in the batch.\n",
    "        pass\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        \n",
    "        #  TODO: call the layers on a batch of input graphs in the forward pass,\n",
    "        #        and return the model classification of each graph in the batch.\n",
    "        \n",
    "        # Hint: x is the tensor with node features, edge_index is the tensor with edge indices,\n",
    "        #       and batch is the tensor containing the index of the graph in the batch that each node belongs to.\n",
    "        \n",
    "        return pred_per_graph # number of rows in this tensor should equal the number of graphs in the batch\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7adbf6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "ce7adbf6",
    "outputId": "2c9f2a3a-3204-4175-95cf-0102dba5d8b0"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Hint: you might want to try running on the cpu first for easier debugging. \n",
    "Additionally, depending on your implementation, the GPU may not even be faster than the CPU.\n",
    "(note that the focus of this assignment is not the efficiency of the implementation on the GPU).\n",
    "'''\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device='cpu'\n",
    "print(f'Loaded device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65a110c",
   "metadata": {
    "id": "c65a110c"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: Train the GNN. Complement the code where applicable (indicated with #  TODO)\n",
    "'''\n",
    "model = ... #  TODO: initialize our GNN\n",
    "model.to(device)  # and move to the GPU, if possible\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())  # adam usually works well\n",
    "loss_func = ...  #  TODO: define a suitable loss function\n",
    "\n",
    "\n",
    "def train():  #  TODO: fill in the missing parts of this function below\n",
    "    \n",
    "    model.train()  # set the model to training mode\n",
    "    \n",
    "    for data in train_loader:  # loop through the training set in a batch-wise fashion\n",
    "        \n",
    "        data.to(device)  # move the batch to the device (GPU if applicable)\n",
    "        optimizer.zero_grad()  # set gradients to 0\n",
    "        \n",
    "        out = model(...)  #  TODO: propagate the data through the model to obtain model output\n",
    "        # Hint: recall the attributes of the data object and the arguments of the model's forward method\n",
    "        \n",
    "        loss = loss_func(...)  #  TODO: calculate the loss based on the model's predictions and the true labels.\n",
    "        \n",
    "        loss.backward()  # derive gradients\n",
    "        optimizer.step()  # update all parameters based on the gradients\n",
    "\n",
    "\n",
    "        \n",
    "def test(loader):  #  TODO: complete the code fo the test function (it should be similar to the train function)\n",
    "    model.eval()  # set the model to evaluation mode\n",
    "    \n",
    "    correct = 0  # keep track of how many we have correct\n",
    "    total = 0  # and how many we handle in total\n",
    "    \n",
    "    for data in loader:  # loop through the supplied dataset in a batch-wise fashion\n",
    "        data.to(device)  # transfer batch to device\n",
    "        \n",
    "        out = model(...)  #  TODO: propagate the data through the model\n",
    "        pred = ... # TODO:  convert the model output to a 0/1 predicted label (for each graph in the batch)\n",
    "                \n",
    "        correct += int((pred == data.y).sum())  # add the number of correct predictions\n",
    "        total += len(data.y)  # and add the total number of elements\n",
    "        \n",
    "    return correct / total  # return the accuracy\n",
    "\n",
    "\n",
    "\n",
    "# the below code is already complete and calls the train and test functions, and prints some statistics\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "epochs = 50\n",
    "start = time.time()\n",
    "for epoch in range(1, epochs+1):  # train for number of epochs\n",
    "    \n",
    "    train()  # do one training step over the entire dataset\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        train_acc = test(train_loader)  # compute the training accuracy\n",
    "        val_acc = test(val_loader)  # compute the validation accuracy\n",
    "    \n",
    "    tic = time.time()\n",
    "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Validation Acc: {val_acc:.4f}. Training time so far: {tic-start:.1f} s')\n",
    "    train_accs.append(train_acc)  # save accuracies so we can plot them\n",
    "    val_accs.append(val_acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86218833",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "86218833",
    "outputId": "c7bc5a5c-5483-4872-b4ee-0ee61ec4b9de"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "To get an overview of the accuracy over the training period, we define a simple function\n",
    "to plot the saved accuracies.\n",
    "'''\n",
    "def plot_train(train_accs, val_accs):\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    fnt=16\n",
    "    ax.plot(train_accs, color='blue', label='Train')\n",
    "    ax.plot(val_accs, color='red', linestyle='--', label='Validation')\n",
    "    ax.legend(fontsize=fnt)\n",
    "    ax.tick_params(axis='both', labelsize=fnt)\n",
    "    ax.set_xlabel('Epoch', fontsize=fnt)\n",
    "    ax.set_ylabel('Accuracy', fontsize=fnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bx3vOYKJE8if",
   "metadata": {
    "id": "bx3vOYKJE8if"
   },
   "outputs": [],
   "source": [
    "plot_train(train_accs, val_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5cf249",
   "metadata": {
    "id": "bd5cf249"
   },
   "source": [
    "# Evaluation and discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XkI9E--qsrxE",
   "metadata": {
    "id": "XkI9E--qsrxE"
   },
   "source": [
    "To conclude, we shortly evaluate the performance of our model, and use it to make predictions. We define a simple function for testing and drawing a single molecule (from the validation set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ID1fhKtir-",
   "metadata": {
    "id": "75ID1fhKtir-"
   },
   "outputs": [],
   "source": [
    "print(f'Final validation accuracy: {val_accs[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0592b7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "ae0592b7",
    "outputId": "701ace0f-a222-4312-d68b-85992b57dd40"
   },
   "outputs": [],
   "source": [
    "def test_sample(idx):\n",
    "    mol = dataset_val[idx]  # take our sample\n",
    "    mol.to(device)  # put it on device\n",
    "    pred = model(mol.x,  # propagate nodes\n",
    "                 mol.edge_index,   #  edges\n",
    "                 torch.zeros(mol.x.shape[0], dtype=torch.long).to(device))  # 'batch' object of 0s (the one graph in the batch)\n",
    "\n",
    "    pred = pred.to('cpu')  # put data back on cpu\n",
    "    mol = mol.to('cpu')\n",
    "    pred = int(pred.argmax(dim=1))  # gather predictions\n",
    "    true = int(mol.y)  \n",
    "    outcome = ['No mutagenicity', 'Mutagenicity']\n",
    "    outcome_text = 'Predicted = \"{}\", Ground-truth = \"{}\"'.format(outcome[pred], outcome[true])  # create outcome text\n",
    "    draw_molecule(mol, title=f'Sample {idx}\\n' + outcome_text)  # draw the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9365a11",
   "metadata": {
    "id": "b9365a11"
   },
   "outputs": [],
   "source": [
    "test_sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZCHMhGnpA1hq",
   "metadata": {
    "id": "ZCHMhGnpA1hq"
   },
   "source": [
    "## Discussion\n",
    "This concludes the practical on graph classification. We have focused on how to use GNNs to classify entire graphs, where the graphs can be of arbitrary size.\n",
    "\n",
    "We credit the Graph Classification tutorial provided by PyTorch Geometric[[3]](#pytorchgeom) as a foundation for this practical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yCaIa48BA2z6",
   "metadata": {
    "id": "yCaIa48BA2z6"
   },
   "source": [
    "# References\n",
    "<a name=\"pytorchgeomintro\"></a>\n",
    "[1] https://pytorch-geometric.readthedocs.io/en/latest/index.html \n",
    "\n",
    "<a name=\"mutagenicity\"></a>\n",
    "[2] Kazius, J., McGuire, R., & Bursi, R. (2005). Derivation and validation of toxicophores for mutagenicity prediction. Journal of medicinal chemistry, 48(1), 312-320.\n",
    "\n",
    "<a name=\"pytorchgeom\"></a>\n",
    "[3] https://pytorch-geometric.readthedocs.io/en/latest/notes/colabs.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80112c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "P4.2_Graph_Classification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
